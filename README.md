# 2022: AI-based Military Decision Support Using Natural Language
Michael Möbius and Daniel Kallfass (Airbus Defence and Space GmbH), Thomas Manfred Doll (Army Concepts and Capabilities Development Centre), and Dietmar Kunde (German Army Headquarters)
## Abstract
To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.
https://informs-sim.org/wsc22papers/207.pdf


# 2021: From the Game Map to the Battlefield – Using DeepMind's Advanced AlphaStar Techniques to Support Military Decision-Makers
Future warfare scenarios featuring fully digital, AI-assisted command and control and the use of unmanned systems will have a dramatic impact on the tempo of combat operations. Consequently, they will put the cycles of military decision-making under even higher time pressure. Modelling and simulation in combination with advanced AI techniques will become key enablers for future decision-support systems. These systems will support military decision-makers in the assessment of threats as well as in developing and evaluating the best possible courses of action for their own forces. The latest developments by AI research companies in the civilian domain, such as DeepMind's AlphaStar, have applied advanced deep reinforcement learning techniques to popular games like StarCraft II to train RL agents to develop superior strategies for beating their opponents.
This paper presents the results of a study conducted by the Army Concepts and Capabilities Development Centre and Airbus. The aim of the study was to evaluate how the aforementioned machine-learning techniques can be adapted and employed to train an RL agent capable of acting as a battalion commander in a combat simulation (“ReLeGSim”). In each time step of this simulation, the RL agent can send orders to the available units/companies or request multi-domain fire support. The “ReLeGSim” simulates the behaviour and combat attrition of each company/unit and fire support element at the level of the individual platform. It then returns feedback (so-called reward) to the RL agent in order to assess and improve its behaviour during the training cycle. It is also possible to select multiple trained RL agents and let them play against each other in a league system to further improve them.
Having undergone such training, the RL agent can be applied to an actual scenario. The resulting strategies can be proposed to the battalion commander as possible courses of action in a decision cycle.
https://www.sto.nato.int/publications/STO%20Meeting%20Proceedings/STO-MP-MSG-184/MP-MSG-184-14.pdf
